{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised classification\n",
    "\n",
    "In the data.csv there are letters (uppercases and lowercases) and numbers, 28x28 pixels in a row format.\n",
    "\n",
    "* First, you need to know which labels are which, meaning you need to visualize some data to realize which number labels represents a letter, or a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = zipfile.ZipFile('data_all.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = zipfile.ZipFile('data_all.zip')\n",
    "\n",
    "df = pd.read_csv(z.open('data_all.csv'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix = [np.array(df.groupby('e').first().loc[i,:]) for i in range(len(df.groupby('e').first()))]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_matrix)):\n",
    "    plt.imshow(df_matrix[i].reshape(28,28))\n",
    "    print(i)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = [float(x) for x in range(0,9)]\n",
    "uppercase = [float(x) for x in range(10,36)]\n",
    "lowercase = [float(x) for x in range(35,62)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_number = df[df.e.isin(number)].reset_index()\n",
    "df_uppercase = df[df.e.isin(uppercase)].reset_index()\n",
    "df_lowercase = df[df.e.isin(lowercase)].reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now, try to train a classifier model to predict the uppercases. Use every single model you know for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNeCla = KNeighborsClassifier()\n",
    "RaFoCla = RandomForestClassifier()\n",
    "Gauss = GaussianNB()\n",
    "SuVeCla = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_uppercase.drop('e',axis=1),df_uppercase.e)\n",
    "\n",
    "KNeCla_UC = KNeCla.fit(X_train,y_train)\n",
    "RaFoCla_UC = RaFoCla.fit(X_train,y_train)\n",
    "Gauss_UC = Gauss.fit(X_train,y_train)\n",
    "SuVeCla_UC = SuVeCla.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_KNeCla_UC = KNeCla.predict(X_test)\n",
    "y_RaFoCla_UC = RaFoCla.predict(X_test)\n",
    "y_Gauss_UC = Gauss.predict(X_test)\n",
    "y_SuVeCla_UC = SuVeCla.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'KNeCla_UC: {accuracy_score(y_KNeCla_UC,y_test)}')\n",
    "print(f'RaFoCla_UC: {accuracy_score(y_RaFoCla_UC,y_test)}')\n",
    "print(f'Gauss_UC: {accuracy_score(y_Gauss_UC,y_test)}')\n",
    "print(f'SuVeCla_UC: {accuracy_score(y_SuVeCla_UC,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest was the most accurate model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try to do the same thing with lowercases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_lowercase.drop('e',axis=1),df_lowercase.e)\n",
    "\n",
    "KNeCla_LC = KNeCla.fit(X_train,y_train)\n",
    "RaFoCla_LC = RaFoCla.fit(X_train,y_train)\n",
    "Gauss_LC = Gauss.fit(X_train,y_train)\n",
    "SuVeCla_LC = SuVeCla.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_KNeCla_LC = KNeCla.predict(X_test)\n",
    "y_RaFoCla_LC = RaFoCla.predict(X_test)\n",
    "y_Gauss_LC = Gauss.predict(X_test)\n",
    "y_SuVeCla_LC = SuVeCla.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'KNeCla_LC: {accuracy_score(y_KNeCla_LC,y_test)}')\n",
    "print(f'RaFoCla_LC: {accuracy_score(y_RaFoCla_LC,y_test)}')\n",
    "print(f'Gauss_LC: {accuracy_score(y_Gauss_LC,y_test)}')\n",
    "print(f'SuVeCla_LC: {accuracy_score(y_SuVeCla_LC,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest was the most accurate model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Try to do the same thing with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_number.drop('e',axis=1),df_number.e)\n",
    "\n",
    "KNeCla_NU = KNeCla.fit(X_train,y_train)\n",
    "RaFoCla_NU = RaFoCla.fit(X_train,y_train)\n",
    "Gauss_NU = Gauss.fit(X_train,y_train)\n",
    "SuVeCla_NU = SuVeCla.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_KNeCla_NU = KNeCla.predict(X_test)\n",
    "y_RaFoCla_NU = RaFoCla.predict(X_test)\n",
    "y_Gauss_NU = Gauss.predict(X_test)\n",
    "y_SuVeCla_NU = SuVeCla.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'KNeCla_NU: {accuracy_score(y_KNeCla_NU,y_test)}')\n",
    "print(f'RaFoCla_NU: {accuracy_score(y_RaFoCla_NU,y_test)}')\n",
    "print(f'Gauss_NU: {accuracy_score(y_Gauss_NU,y_test)}')\n",
    "print(f'SuVeCla_NU: {accuracy_score(y_SuVeCla_NU,y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest was the most accurate model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
